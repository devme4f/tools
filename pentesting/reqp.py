#!/usr/bin/env python3
import requests, sys, threading, argparse
from time import sleep

parser = argparse.ArgumentParser()
parser.add_argument('-f', '--file', help='file contain urls to check')
parser.add_argument('-p', '--pattern', help='pattern to looking for')
parser.add_argument('--payload', help='payload to replace FUZZ')
parser.add_argument('-t', '--thread', type=int, default=3, help='number of threads, default is 3')
parser.add_argument('-s', '--sleep', type=float, default=0.2, help='time to sleep each thread, default is 0.2')
parser.add_argument('-b', '--begin', type=int, default=0, help='index to begin, default is 0')
args = parser.parse_args()

filename = args.file
pattern = args.pattern
payload = args.payload
thread_num = args.thread
t2s = args.sleep
begin = args.begin

print('Loading the file.......')
with open(f'{filename}', 'r') as f:
        urls = [x.strip() for x in f.read().split('\n')]

def checker(url, i):
        try:
                url = url.replace('FUZZ', payload)
                r = requests.get(url, timeout=5)
                if pattern in r.text:
                        print(url)
        except requests.exceptions.RequestException:
                pass

threads = []

print('Pattern found in urls: \n')
length = len(urls)
i = begin
while i < length:
        t = threading.Thread(target=checker, args=[urls[i], i])
        t.start()
        threads.append(t)

        if i % 1000 == 0:
                print(f'[DONE] - {i} requests!')

        if i % thread_num == 0:
                for thread in threads:
                        thread.join()
                threads = []
                sleep(t2s)
        i += 1
